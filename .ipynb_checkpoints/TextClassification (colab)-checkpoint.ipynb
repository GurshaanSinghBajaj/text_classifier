{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rXi91WaTNtTh"
   },
   "outputs": [],
   "source": [
    "## All the import statements\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "import urllib.request\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from string import punctuation\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9vFfIqn1NtTn",
    "outputId": "78603cd3-5351-422d-ccdf-561759264970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "a=[]\n",
    "classes=[\"alt.atheism\",\"comp.graphics\",\"comp.os.ms-windows.misc\",\"comp.sys.ibm.pc.hardware\",\n",
    "         \"comp.sys.mac.hardware\",\"comp.windows.x\",\"misc.forsale\",\"rec.autos\",\"rec.motorcycles\",\n",
    "         \"rec.sport.baseball\",\"rec.sport.hockey\",\"sci.crypt\",\"sci.electronics\",\"sci.med\",\n",
    "         \"sci.space\",\"soc.religion.christian\",\"talk.politics.guns\",\"talk.politics.mideast\",\n",
    "         \"talk.politics.misc\",\"talk.religion.misc\"]\n",
    "\n",
    "print(len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "Bz78o_qLNtTs",
    "outputId": "4386b351-7e74-4c5b-b9cf-364b63a41de3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "{'here', 'that', 'hadn', 'or', 'down', 'had', 'it', \"should've\", 'itself', 'this', 'during', 'themselves', 'into', 'hasn', 'whom', 'which', 'he', 'their', 'are', 'having', 'most', 'ourselves', \"shan't\", 'you', \"isn't\", 'aren', 'up', 'all', \"wouldn't\", 'yourself', 'd', 'some', 'out', 'wasn', 'while', 'yourselves', 'for', 'a', 'few', 'each', 'weren', 'mightn', 'didn', 'himself', 'above', 'ain', 'off', 'from', 'both', 'does', 'be', \"needn't\", 'who', 'these', 'not', 'ma', \"you'd\", 'there', 'to', 'were', 'nor', 'with', 'yours', 'more', 'same', 'has', \"that'll\", 'other', 'its', 'such', 'any', 'only', 'against', 'we', 'me', 'very', 'isn', 'am', \"haven't\", 'so', 'if', 'is', 'between', 'on', 'under', 've', 'our', 're', 'ours', 'his', 'being', 'your', 'an', 'the', 'but', 'further', 'o', \"mustn't\", 'why', 'm', 'about', 'theirs', 'what', \"you've\", 'once', 'too', 't', \"wasn't\", 'they', 'again', 'herself', 'do', 'how', 'my', \"hadn't\", 'myself', \"doesn't\", 'will', \"hasn't\", 'just', \"it's\", 'doing', 'll', 'through', \"aren't\", 'needn', 'shouldn', 'been', 'by', 'wouldn', \"didn't\", 'she', \"you'll\", 'have', 'now', 'because', 'where', 'when', 'shan', \"mightn't\", 'than', 'before', 'should', 'him', 'in', 'no', 'of', 'can', 'over', 'as', 'own', 'won', 'couldn', 'haven', 'until', 'i', 'her', 'at', 'don', \"she's\", \"you're\", \"shouldn't\", \"won't\", 'those', 'was', 'them', 'below', 'doesn', 'y', 'and', 'then', 's', 'after', \"weren't\", 'hers', 'did', 'mustn', \"don't\", \"couldn't\"}\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "StopWords=set(stopwords.words('english'))\n",
    "print(StopWords)\n",
    "# Our own list of some block words to be avoided   \n",
    "block_words = ['newsgroups', 'xref', 'path', 'from', 'subject', 'sender', 'organisation', 'apr',\n",
    "               'gmt', 'last','better','never','every','even','two','good','used','first','need',\n",
    "               'going','must','really','might','well','without','made','give','look','try','far',\n",
    "               'less','seem','new','make','many','way','since','using','take','help','thanks','send',\n",
    "               'free','may','see','much','want','find','would','one','like','get','use','also','could',\n",
    "               'say','us','go','please','said','set','got','sure','come','lot','seems','able','anything',\n",
    "               'put', '--', '|>', '>>', '93', 'xref', 'cantaloupe.srv.cs.cmu.edu', '20', '16', \n",
    "               \"max>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'\", '21', '19', '10', \n",
    "               '17', '24', 'reply-to:', 'thu', 'nntp-posting-host:', 're:','25''18'\"i'd\"'>i''22''fri,''23''>the',\n",
    "               'references:','xref:','sender:','writes:','1993','organization:']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "a9os1ahLNtTv",
    "outputId": "ba564a50-bf92-4cd3-dcbf-86d18709ca79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'?', '|', '$', '^', '!', '%', '#', '(', '=', '/', '>', \"'\", ')', '~', '<', ']', '.', '@', ',', '&', '_', '*', '\\\\', '`', '{', '+', '[', '}', '\"', ';', '-', ':'}\n"
     ]
    }
   ],
   "source": [
    "punc = (set(punctuation))\n",
    "print (punc)\n",
    "num = {'0','1','2','3','4','5','6','7','8','9'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dgwb5ar_NtTy"
   },
   "outputs": [],
   "source": [
    "data={}\n",
    "data[\"train\"]={}\n",
    "data[\"test\"]={}\n",
    "for i in range(20):\n",
    "    s=classes[i]\n",
    "    data[s]=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "QVDn1BJDOU3f",
    "outputId": "ac4bb549-a922-453b-8d72-efd4f7325aec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a.tar.gz', <http.client.HTTPMessage at 0x7f50134c3ac8>)"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve (\"https://archive.ics.uci.edu/ml/machine-learning-databases/20newsgroups-mld/20_newsgroups.tar.gz\", \"a.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tS74QwacOWag"
   },
   "outputs": [],
   "source": [
    "\n",
    "tar = tarfile.open(\"a.tar.gz\")\n",
    "tar.extractall()\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8e9w6OiVNtT1"
   },
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    a.clear()\n",
    "    for files in os.listdir(\"./20_newsgroups/\"+classes[i]):\n",
    "        data[classes[i]].append(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8XdTRnX4NtT3"
   },
   "outputs": [],
   "source": [
    "word_present={}\n",
    "alternate_word_array=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jftfRzxONtT5"
   },
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    for j in range(len(data[classes[i]])):\n",
    "        path = \"./20_newsgroups/\"+classes[i]+\"/\"+data[classes[i]][j]\n",
    "        text = open(path, 'r', errors='ignore').read()\n",
    "        for word in text.split():\n",
    "            word=word.lower()\n",
    "            if word not in StopWords and word not in block_words:\n",
    "                if word in word_present and word:\n",
    "                    word_present[word]+=1\n",
    "                else:\n",
    "                    word_present[word]=1\n",
    "                    alternate_word_array.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "AV07g-NXNtT7",
    "outputId": "99093092-07fb-43ce-beb4-f2a9ac106a9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425256\n",
      "<class 'list'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(len(word_present.keys()))\n",
    "print(type(alternate_word_array))\n",
    "print(type(alternate_word_array[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "iyFqPvjENtT_",
    "outputId": "19a83be0-6699-46d4-c70f-b6cd66965ea9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189244\n"
     ]
    }
   ],
   "source": [
    "x=[]\n",
    "for s in alternate_word_array:\n",
    "    last=0\n",
    "    word_array=[]\n",
    "    j=0\n",
    "    for i in range(len(s)):\n",
    "        if s[i] in punc:\n",
    "            j+=1\n",
    "            if last!=i:\n",
    "                word_array.append(s[last:i])\n",
    "            last = i+1\n",
    "    if last != len(s):\n",
    "        word_array.append(s[last:])\n",
    "    if len(word_array)>=2:\n",
    "        for c in word_array:\n",
    "            if c in word_present:\n",
    "                word_present[c]+=1\n",
    "            else:\n",
    "                word_present[c]=1\n",
    "    if j>0:\n",
    "        x.append(s)\n",
    "        \n",
    "for i in x:\n",
    "    del word_present[i]\n",
    "    \n",
    "print(len(word_present.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "752NM7_VNtUB",
    "outputId": "c8f755dd-2d20-4c4e-dbc2-4bc2fd8c3fca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94899\n"
     ]
    }
   ],
   "source": [
    "x.clear()\n",
    "for s in word_present.keys():\n",
    "    for i in range(len(s)):\n",
    "        if s[i] in num:\n",
    "            x.append(s)\n",
    "            break\n",
    "for i in x:\n",
    "    del word_present[i]\n",
    "print(len(word_present.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "idvCeQ2kNtUE",
    "outputId": "b0254712-616b-4915-b271-0779134a3114"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2398\n"
     ]
    }
   ],
   "source": [
    "x.clear()\n",
    "for s in word_present.keys():\n",
    "    if word_present[s] <= 200:\n",
    "        x.append(s)\n",
    "for i in x:\n",
    "    del word_present[i]\n",
    "print(len(word_present.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tzPFFYJkNtUH"
   },
   "outputs": [],
   "source": [
    "final_words=[]\n",
    "for i in word_present.keys():\n",
    "    final_words.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "iyzfmsiXNtUJ",
    "outputId": "61697173-e2db-44f7-ccc6-fd7889375681"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['path:', 'newsgroups:', 'alt.atheism', 'subject:', 'death', 'penalty', '/', 'war', 'message-id:', 'from:', 'date:', '22', 'u', 'cs', 'lines:', '44', 'article', '(mark', '>in', '-', \"that's\", 'stuff.', '>i', 'heard', '...', '>>and', 'follow', 'means', 'seen', 'place', 'hit', 'close', 'higher', 'source', 'says', 'count', 'excuse', 'me,', 'mean', 'claiming', 'different', 'bill', 'happens', 'main', '(i', 'think', 'still', 'others', 'include', 'nation', 'rest', 'claim', 'city', 'water', \"can't\", 'handle', 'exactly', 'all,', \"i'm\", 'sure,', 'media', 'case,', 'know', 'relevant', 'move', 'somewhere', 'cross', \"here's\", \"he's\", 'page', 'member', 'league', 'programming', 'freedom', 'write', 'jews', '(usenet', 'news)', 'canada', 'tue,', '6', '40', '(jon', '>the', 'poster', 'years', 'jewish', 'history,', 'people', 'problem', 'pretty', 'part', '2000', 'years,', 'thinking', 'instead', 'important', 'original', 'bit', 'killing', 'thing', 'originally', 'saw', 'ken', 'came', 'strong', 'though.', 'advice', 'argue', 'someone', 'idea', 'little', 'least', 'right.', 'nazi', 'party', 'gone', 'active', 'support', 'man', 'though', 'perfectly', '>', 'understand', 'matter', 'throughout', 'articles', 'thread', 'that,', 'maybe', 'bad', 'reading', 'probably', 'true', 'often', 'charge', 'gets', 'around', 'order', 'legitimate', 'state', 'anyway,', \"i'd\", 'rather', 'doug', 'opinions', 'wrong', '3', 'california', 'institute', 'technology,', '25', 'turkish', 'guy', 'tried', 'decided', 'facts', 'point', 'atheists', 'reality', 'looked', 'blue', 'truth', 'god', 'view', 'big', 'return', 'looks', 'universe', ':)', '23', 'distribution:', 'world', 'department', 'computer', 'science,', 'university', 'mark', 'wrote:', ':', 'indeed', 'explain', 'international', 'figure', 'missed', 'took', 'it,', 'regardless', 'whether', 'methods', 'time', 'claimed', 'rate', 'meant', 'back', 'intended', 'al', 'all.', '(mike', '(was', 'political', 'x-newsreader:', 'tin', '[version', '1.1', 'pl9]', 'est', '37', '(bill', '>this', 'defend', 'homosexuality', '>as', 'population', 'values', 'capital', 'according', 'something', 'cannot', 'case', 'talking', 'abortion', 'homosexual', 'sex', 'choice', 'sometimes', 'happen', 'went', 'resolution', 'education', 'best', 'atheist', 'object', 'sorry', 'logic', 'me.', 'making', 'specific', '>and', 'here,', 'basis', 'mike', '|', 'choose', 'ignore', 'it.', 'old', '(dan', 'e', 'morality', 'communications', 'company', 'sat,', '14', 'actions', 'another', '(as', 'per', 'personal', ':-)', 'majority', 'right?', 'question', 'sense', '\"what', 'makes', 'dan', 'talk.abortion,alt.atheism,talk.religion.misc', \"i'll\", 'raise', 'originator:', 'national', 'usa', 'fri,', '(david', '(frank', \"o'dwyer)\", '>>>', '(peter', 'create', 'theory', 'prove', 'therefore', '31', 'kind', 'post', 'christianity', '>are', 'newsgroup', 'posts', 'response', 'christian', 'posting', '\"you', \">i'm\", 'enough', 'bible', 'false', 'name', 'god.', 'obvious', 'time.', '>but', 'carry', 'power', 'merely', 'line.', 'course', 'religion,', 'hard', 'atheism', 'words,', 'read', 'faq', 'david', 'become', 'learn', 'j.', 'alt.atheism,talk.religion.misc,talk.origins', 'california,', 'natural', 'history', 'mr.', 'nearly', 'complete', 'certainly', 'definitely', 'modern', 'human', 'either.', 'consider', 'small', 'large', 'saying', 'allowed', 'thu,', '15', 'followup-to:', 'islamic', 'statement', 'systems', 'working', 'world.', 'however', 'stand', 'actually,', 'nothing', '---', 'private', 'activities', 'net.', 'genocide', 'caused', 'computing', '(keith', 'm.', 'humans', 'everything', 'existence', 'anybody', '\"i', 'men', 'women', 'measure', 'yet', 'one.', 'stupid', '9', 'disclaimer:', 'agree', '(eric', '-0700', 'frank@d012s658.uucp', 'worth', 'damn', 'hardly', 'word', 'again.', 'possibility', 'interested', 'knowing', 'believe', 'science', 'likely', 'truth,', 'value', 'decision', 'getting', \"what's\", 'example,', 'necessarily', '(in', 'assuming', 'technology', 'fit', 'argument', 'here.', 'asking', 'life', 'refer', 'clear', 'second', 'note', 'connection', 'not.', 'issue', 'result', 'understanding', 'wanted', 'things', 'necessary', 'results', 'allow', 'ibm', 'care', 'quite', '(i.e.', 'shown', 'showing', 'points', 'etc.', 'words', '>to', 'mean,', 'no,', 'scientific', 'problems', '(for', 'problems.', 'concept', 'des', 'box', 'work', 'objective', 'again,', 'discuss', 'effect', '\"it', 'works', 'thing,', 'course,', 'essentially', 'sorry,', 'english', 'based', 'that.', 'clearly', 'eric', \"we've\", 'wed,', 'usenet@news.cso.uiuc.edu', '(net', 'noise', 'owner)', 'illinois', 'urbana', 'various', \"i've\", 'started', 'book', 'called', 'nature', 'stated', 'religious', 'terms', 'events', 'quote', 'section', 'examples', 'gave', 'parts', 'mac', 'michael', 'a.', 'taxes', 'middle', 'class', 'pay', 'clinton', '3rd', 'debate', 'nobody', 'sgi', 'question,', 'possible', 'holding', '(the', 'you,', 'sit', 'open', 'alternative', 'life.', 'opinion', 'actually', 'easy', '(was:', '#', 'strongly', 'belief', 'neither', 'leads', 'is,', 'chance', 'tend', 'towards', 'times', 'conclusion', 'basic', 'behind', '#>', 'up.', 'useful', 'true,', 'up,', 'evidence', 'point.', 'information', 'person', 'information.', 'special', 'features', 'lack', 'on,', 'dangerous', 'sources', 'none', 'things.', 'especially', 'leaders', 'frank', 'living', 'wonder', 'discussion', 'left', 'fact,', 'starts', 'easily', 'benefit', 'proof', 'followed', 'practice', 'anyone', 'almost', 'pass', 'catholic', 'church', 'grant', 'you.', 'ever', 'usually', 'discussions', 'written', 'comes', 'common', 'simply', 'before,', 'trying', 'however,', 'already', 'beliefs', 'allows', 'switch', 'takes', 'way,', 'them.', 'talk', 'whole', 'opposed', 'did.', 'asked', 'religion', 'interesting', 'nice', 'found', 'either', 'aware', 'giving', 'everyone', 'rights', 'always', 'wish', 'define', 'reason', 'upon', 'long', 'process', 'analysis', 'contain', 'it?', 'self', 'reference', 'within', 'systems,', 'learned', 'risk', 'hearing', '\"we', 'hear', \"we're\", 'back.', 'deal', 'thinks', 'buy', 'somehow', 'accept', 'leave', 'claims', 'statements', 'totally', 'feel', 'them,', 'contains', 'despite', 'data', 'system', 'yes,', 'arguments', 'show', 'this.', 'needs', 'else', 'supposed', 'information,', '\"the', 'are.', 'general', 'true.', 'obtain', 'speaking', 'larger', 'way.', 'test', 'point,', 'particular', 'anyway.', 'method', 'then,', 'do,', 'requires', 'suspect', 'definition', 'effects', 'connected', 'and/or', 'hold', 'treatment', 'well.', 'fair', 'b', 'sounds', 'waste', 'possible.', 'depending', 'example', 'others.', 'tell', 'holy', 'ordered', 'highly', 'mention', '(jim', '-0400', 'inc.', '26', 'perhaps', 'week', 'appears', 'news', 'software', 'hole', '(tom', 'done', 'stay', 'top', 'fall', '[...]', 'days', 'messages', 'days.', 'changing', 'jobs', 'track', 'end', 'room', 'given', 'jim', 'inc.,', 'system)', 'heavy', 'cut', 'admit', 'level', 'good,', 'thus', 'so,', 'assume', 'mathew', 'mon,', '8', 'soldiers', 'job', 'following', 'positive', 'beyond', 'keywords:', 'start', 'right', 'well,', 'hope', 'convert', '>it', 'jesus', '(', 'day', 'significant', 'is.', 'life,', 'total', \"god's\", 'sell', 'keith', 'moral', 'agency', 'faith', 'wondering', 'question:', 'standard', '>that', 'now.', 'business', 'unit', 'via', '(joseph', 'types', 'capable', 'reaction', 'several', 'first,', 'activity', '*not*', 'future', 'except', 'independent', '(this', 'also,', 'current', 'previous', 'models', 'model', 'evolution', 'front', 'turned', 'event', 'impossible', 'valid', 'discovered', 'relatively', '30', 'spent', 'held', 'fact', 'spend', 'pointed', 'apparently', 'hundred', 'later,', 'described', '\"a', 'offered', '$1', 'land', 'sound', 'correct', 'price', '(robert', '18', '=', 'disagree', '(not', 'prefer', 'bob', '(michael', 'l.', 'summary:', 'at&t', 'bell', 'background', 'behavior', 'among', 'major', 'now,', 'social', 'action', 'books', 'difficult', 'later', 'playing', 'individual', 'setting', 'people,', 'becomes', 'otherwise', 'entire', 'context', 'single', 'thousands', 'day,', 'along', 'language', '(which', 'window', 'shall', 'love', 'boston', 'physics', '35', '(ken', '>>i', 'group', '>>the', 'i,', 'group,', 'views', 'supports', 'answer', 'judge', 'islam', 'status', 'muslim', 'historical', 'college', '38', 'months', 'remember', 'goes', 'there,', 'recognize', 'else.', 'gotten', 'degree', 'keep', 'tom', 'respect', 'longer', 'services', 'internet', 'regards,', '*', 'john', 'thought', 'r', '13', 'generally', 'accepted', 'outside', 'countries', 'mother', 'lead', 'spread', '>on', 'above.', 'virginia', 'tech', 'va', '46', 'issues', 'present', \"let's\", 'control', 'woman', 'opinion,', 'relationship', 'effort', 'levels', 'about.', 'link', '__', '\\\\', '_/', '1.', 'beginning', 'created', \"we'll\", 'billion', '(james', 'thomas', 'university,', 'san', '11', 'ask', 'states', 'james', 't.', 'green', '(brian', 'research', '7', '(and', 'space', 'limit', 'screen', 'stuff', 'brian', 'hand', 'blood', 'sort', 'particularly', 'western', 'whatever', 'muslims', 'fear', 'fine', 'concerned', 'yes', 'on.', 'unfortunately,', 'comments', 'attempts', 'specifically', 'met', 'references', 'text', 'line', '()', 'ny', '>what', 'difference', 'calling', 'providing', 'accurate', 'say,', 'kill', 'serve', 'speak', 'shows', 'changes', 'record', 'provide', 'reserve', 'dr.', '>a', 'anywhere', 'society', 'putting', 'failed', 'believed', 'in.', 'three', '1)', '2)', '3)', 'know.', '>my', 'attack', 'guess', 'reasonable', 'huge', 'chip', 'names', 'mind', \"they're\", 'sun,', 'law', '\"', 'laws', 'local', 'family', 'technical', 'germany', 'v.', 'b.', '>is', 'third', 'length', 'passed', 'actual', 'standards', '2', '12', 'depends', 'and,', 'attempt', 'apply', '27', 'fundamental', 'list', 'usual', 'summary', 'afraid', 'god,', 'term', 'paper', 'exists', 'worse', 'provided', 'request', 'recently', 'contact', 'net', 'email', 'thanks,', '5', 'texas', 'wrong,', 'seeing', 'situation', 'other.', 'brother', 'played', '36', '2nd', 'simple', 'do.', 'bring', 'meaning', 'internal', 'owners', 'account', 'network', 'i.e.', 'number', 'objects', 'exist', 'stop', 'missing', 'live', 'christians', 'interest', 'shoot', 'million', 'position', 'murder', 'etc.)', '(like', '>they', 'suppose', 'ideas', 'letters', 'real', 'santa', 'notice', 'lots', '.', 'g', 'hate', 'taken', 'energy', 'devices', 'supply', 'perfect', 'solution', 'associated', 'call', 'build', 'east', 'in-reply-to:', 'wrong.', 'serious', 'yeah,', '>if', 'obviously', 'knowledge', '(to', 'uses', 'replace', 'side', 'eternal', 'similar', 'available.', 'presented', 'unless', '(news', 'administrator)', 'school', 'medicine', 'pick', 'court', 'join', 'sitting', 'ancient', 'personally', 'secure', 'children', 'addition', 'chris', 'purdue', 'engineering', 'german', '(or', 'friend', 'latest', 'selling', 'hot', 'powerful', 'innocent', 'considered', 'due', 'absolutely', 'blame', 'system.', 'system,', 'members', 'drives', 'traffic', 'surely', 'killed', 'driving', '>so', 'includes', 'yes.', 'places', 'copy', 'appear', 'began', 'added', 'material', 'existing', 'basically', 'mountain', 'game', 'c.', '+', 'peace', 'closed', 'yet,', ')', 'lived', 'year', 'reasons', 'night', \"one's\", 'minority', 'city,', 'street', 'tv', 'next', 'let', 'fax', '>--', 'de', 'digital', '33', 'cost', 'vs', 'although', 'cover', 'area', 'justify', 'turn', 'base', 'though,', '(but', 'change', 'biblical', '>|>', 'rules', '>you', 'causes', 'evil', '>there', 'time,', '>of', 'legal', 'update', 'break', 'alone', 'wrote', 'this:', 'fine.', 'spirit', 'absolute', 'limited', 'us.', 'form', 'somewhat', 'light', 'message', 'better.', 'replaced', 'ok', 'included', 'not,', 'advantage', 'questions', 'question.', '49', '#|>', 'recent', 'four', 'writes', 'southern', 'away', 'that?', 'country', 'civil', 'official', 'constitution', 'more.', '32', 'crime', 'p', 'committed', 'c', 'x', 'physical', 'lab', 'united', 'uk', 'law,', 'automatic', 'so.', 'pressure', 'sites', 'red', 'received', 'british', 'government', 'ability', 'telling', \"who's\", 'money', 'full', 'imagine', 'edt', '(scott', 'd.', 'says:', 'final', 'doubt', '28', 'knew', 'things,', 'know,', 'black', 'paul', '>>in', 'parallel', 'coming', 'including', 'mass', 'place.', 'drop', 'but,', 'gives', 'reach', 'math', 'check', 'popular', 'proper', 'near', '(if', 'properly', 'north', 'south', 'earth', 'earlier', 'suggested', 'says,', 'frame', 'amount', 'onto', 'separate', 'ones', 'late', 'too,', 'inside', 'older', 'looking', '___', 'hall', 'j', 'nasa', 'flight', 'center', 'nec', 'tx', '>for', 'ago.', 'showed', '(at', 'joe', 'regard', 'normal', 'cases', 'head', 'public', 'you?', 'hands', 'five', 'answers', 'complex', 'forget', 'west', 'sexual', 'memory', 'disease', 'aids', 'everybody', 'completely', 'brought', '==', 'deleted', 'step', 'logical', 'age', 'stick', 'why?', 'error', 'errors', 'random', 'drug', 'are,', 'no.', 'applied', 'w', '-0500', 'fairly', 'right,', 'policy', '>with', '***', 'talk.religion.misc', 'program', 'purpose', 'quality', 'quoted', 'known', 'taking', 'respond', 'dave', 'excellent', 'together', 'bunch', 'willing', 'jeff', 'couple', 'versions', '?', '(stephen', 'ok,', 'good.', 'face', 'shot', 'extremely', 'justice', '53', 'supported', 'regarding', 'vs.', 'deleted]', '>have', 'proposed', 'hand,', 'high', '29', '(chris', 'nuclear', 'this,', 'extra', 'feeling', 'force', 'entirely', 'certain', 'series', 'privacy', 'function', 'input', 'code', 'great', 'role', 'u.s.', 'study', 'image', 'thanks.', 'road', 'michigan', 'engineering,', 'suggest', 'poor', 'ray', 'robert', 'built', 'sale', 'weapons', 'thing.', 'plus', 'military', 'concerning', 'sun', 'orbit', 'surprised', 'too.', 'lines', 'moon', 'carnegie', 'pittsburgh,', 'pa', 'article,', 'sign', 'ago', '39', 'greater', 'down,', 'loss', 'e-mail:', 'unix', 'users', '4', 'told', '??', 'world,', 'launch', 'defined', 'fuel', 'air', '1', 'type', 'truly', 'computers', 'florida', 'heart', 'named', '55', \"there's\", 'knows', 'day.', 'beat', 'one,', 'gas', 'toward', 'station', 'groups', 'expect', 'felt', 'exact', 'na', 'cheap', 'jack', 'friends', 'watching', '50', 'piece', 'title', 'report', 'wants', 'seriously', 'file.', 'noticed', 'mail', 'kinds', 'author', 'year,', 'solid', 'themselves.', '(1)', '(2)', 'tools', 'intelligence', 'advanced', 'division', 'die', 'waco', 'died', 'expressed', 'mine', 'f.', '>how', 'to.', 'him.', 'what?', 'review', 'us,', 'away.', 'determine', 'usenet', 'postings', 'born', 'rule', 'direct', 'mentioned', 'young', 'differences', '(john', 'e.', 'percent', ']', 'involved', 'generation', 'fixed', 'americans', 'anonymous', 'play', 'weapon', 'oh', '&', 'stanford', 'ca', '52', 'worry', 'warrant', 'changed', 'numbers', 'period', 'half', 'case.', 'suggestions', 'realize', 'criminals', 'lives', '(paul', 'md', '43', 'lost', 'happened', 'win', 'attitude', 'default', 'seemed', 'clipper', 'project', 'documentation', 'early', 'european', 'sick', 'people.', 'equal', '>not', 'shots', 'address', 'continue', 'community', 'tells', 'raised', 'running', 'advance', 'e-mail', 'remove', 'experience', 'approach', 'across', '2.', 'act', 'brain', 'interface', 'escape', 'defense', 'easier', 'short', 'straight', '3.', 'thank', 'group.', 'offer', '4.', 'became', '5.', 'avoid', 'version', 'pain', 'much.', 'drawing', 'years.', 'ftp', 'site', 'r.', '(bob', 'happy', 'professor', 'student', 'andrew', 'available', 'use.', 'rid', 'folks', 'deaths', 'size', 'mostly', 'citizens', 'mission', 'goal', 'save', 'vote', 'him,', 'roads', 'finding', 'smaller', 'percentage', 'ago,', 'be.', 'police', 'gun', 'la', 'quick', 'king', 'decide', 'worked', 'trial', 'video', 'protect', 'sciences', 'dept.', '>would', 'compare', 'master', 'work.', 'application', 'listen', 'add', 'compatible', 'food', 'health', 'eat', 'field', 'whose', '59', 'worst', 'trust', 'wait', '(see', 'wife', 'to,', 'bear', 'home', 'today.', 'et', 'to:', 'require', '100', 'turks', 'radio', 'hours', 'host', 'directly', 'cause', 'authority', 'scott', 'creation', 'areas', '80', 'g.', 'son', 'story', 'father', 'meet', 'needed', 'info', '//', 'this?', 'run', 'ground', 'machines', 'readers', 'considering', '}', 'possibly', 'individuals', 'starting', 'writing', 'pl8]', 'broken', 'moved', 'past', 'today,', 'comment', 'purchase', 'american', 'store', 'placed', 'published', 'receive', 'copies', 'reports', 'oh,', 'reply', 'forward', 'entry', 'kept', 'related', 'electronic', 'said.', 'posted', 'begin', 'gm', 'cars', 'writes...', 'greek', 'addition,', 'quickly', 'reported', 'ms.', 'date', 'ad', 'rich', 'file', 'led', 'remain', 'guide', 'australia', 'library', 'compared', 'brand', '[', 'strange', 'therefore,', 'responsible', '(dave', 'branch', 'cult', 'laboratory', 'ten', 'koresh', 'seven', 'pages', 'decent', 'multiple', 'access', 'kids', 'finally', 'design', '48', 'criminal', 'fighting', 'etc', 'acts', 'protection', 'n', 'cleveland,', 'ohio', '(usa)', '41', '%', 'virtual', ';-)', 'typical', 'game.', '->', 'contact:', 'sales', 'today', 'univ.', 'congress', 'trouble', 'weeks', 'turns', 'produce', 'appreciate', 'work,', 'door', 'share', 'st.', 'morning', 'slightly', 'k', 'bbs', 'telephone', 'moment', 'runs', 'matthew', 'q', 'eventually', 'turkey', 'commercial', 'forced', 'flames', 'armed', 'fbi', 'steve', 'somebody', 'responsibility', 'maintain', 'car', 'said,', 'pro', 'troops', 'male', 'medical', 'recommend', 'ways', 'required', 'opportunity', 'child', 'christ', 'fast', 'command', 'april', 'u.', 'dead', 'signal', 'designed', 'cards', 'watch', 'studies', 'persons', 'law.', 'carried', 'fully', 'expected', 'immediately', 's.', 'attacks', 'games.', 'listed', 'option', 'calls', 'p.', 'richard', 'search', 'magazine', 'letter', 'fun', 'alan', 'minnesota', 'out,', 'summer', 'serial', 'server', 'phone:', 'email:', '45', 'property', 'description', 'arms', 'soon', 'client', 'clean', 'color', '47', 'daily', 'recall', '(steve', '0', '(a', 'express', 'uucp:', 'standing', 'problem,', 'fight', '42', 'frequently', 'options', '..', ',', 'george', 'washington', 'plan', 'six', 'pin', 'problem.', 'dog', 'drive,', 'tax', 'drivers', 'v', 'moving', 'increase', 'external', 'speed', 'pgp', 'key', 'h.', '34', 'wide', 'gay', 'parents', 'cold', 'ensure', 'extended', 'baseball', '$', 'table', 'heaven', 'hell', 'academic', 'resources', 'format', 'draw', 'electrical', '51', 'load', 'provides', 'former', 'character', 'news-software:', 'vax/vms', 'vnews', '1.41', '+1', 'plain', 'visual', 'prevent', 'ed', 'game,', 'washington,', 'ready', 'btw,', 'corporation,', '(andrew', 'owner', 'guys', 'bought', 'paying', 'bank', 'buying', \"they'll\", '>:', 'sin', 'potential', 'mary', \"they've\", 'account)', 'europe', '\"if', 'ahead', 'sets', 'n.', 'offers', 'bet', 'toronto', 'army', 'board', '!', 'voice', 'office', 'approved:', 'regular', 'files', '(richard', '(tim', 'document', '2,', 'connect', 'directory', 'there.', 'files.', '6.', 'nt', 'normally', 'peter', 'denver', 'sent', 'advance.', 'ice', 'yet.', 'note:', 'lord', 'israel', 'off,', 'bodies', 'body', 'white', 'paid', 'miles', 'details', 'government,', 'government.', 'tool', 'lose', 'building', 'america', 'foreign', 'oil', 'drive', 'car,', 'sending', 'programs', 'ii', 'smith', 'program,', 'mormons', 'secretary', 'york', 'joseph', 'operation', 'market', 'development', 'article-i.d.:', 'nj', 'primary', 'computer,', 'ron', 'transfer', 'picture', 'flame', 'developed', 'illegal', 'security', 'committee', 'costs', 'average', 'display', 'mode', 'soviet', '1992', 'organization', 'drugs', 'cup', 'environment', 'doctor', 'june', '6,', 'davidians', 'out.', 'condition', 'safe', 'round', 'operating', 'students', 'convention', 'president', 'central', 'pull', 'weight', '64', 'effective', 'lets', 'online', 'press', '70', 'pat', 'attention', '7.', 'trade', 'proposal', 'forces', 'currently', 'music', 'p.o.', '3d', 'francisco', 'mailing', 'is:', 'ball', 'fax:', 'k.', 'remote', 'laser', 'star', 'doctors', 'volume', 'card', 'range', 'archive', 'performance', 'canadian', 'throw', 'sold', 'conference', 'h', 'prior', 'initial', '<', 'stats', '60', 'ram', 'fire', 'palestinian', 'machine', 'minor', 'additional', 'amendment', 'biggest', '(no', 'variety', 'keeping', 'greatly', 'austin', 'israeli', 'l', 'wire', 'hi,', 'stopped', '@', 'tear', 'help.', 'algorithm', 'patients', 'bits', 'product', 'products', 'fans', 'solar', 'low', 'circuit', 'device', 'output', 'engine', 'compression', '(with', 'heat', 'house', 'stanley', 'secret', 'develop', 'prices', 'equipment', 'service', 'park', 'compound', 'afford', 'print', 'keyboard', '200', 'off.', 'art', '||', 'games', 'released', 'economic', 'il', 'user', 'larry', '2.5', 'chicago', 'town', 'atf', 'los', 'month', 'players', 'manager', 'passes', '**', 'federal', 'next?', 'van', 'images', 'hi', '1st', 'sports', 'william', 'id', 'covered', '----------------------------------------------------------------------', 'appreciated.', 'lower', 'safety', 'corporation', 'internet:', 'release', '1991', 'carrying', 'officers', 'assault', 'soc.religion.christian', 'double', 'reduce', 'car.', 'ford', '1,', '#1', 'appropriate', 'port', 'waiting', 'audio', 'slow', 'holocaust', 'hardware', 'wings', 'f', 'license', 'phone', 'cdt', 'industry', '------', 'apple', 'expensive', 'vitamin', 'march', 'applications', 'teams', 'functions', 'manual', 'team', 'company,', 'management', 'agents', 'hockey', 'crypto', 'keys', 'nsa', 'wiretap', 'sci.crypt', 'enforcement', 'guns', 'w.', '(charles', 'export', 'ms', 'surface', 'distributed', 'communication', 'fan', 'rob', 'ride', 'riding', 'feature', 'tim', '----', 'arab', 'gateway', 'hp', 'comp.graphics', 'windows', 'graphics', 'cpu', 'mit', 'processing', 'pittsburgh', 'bus', 'registration', 'pc', 'printer', 'college,', '3.1', '3.0', 'disk', 'vga', 'diamond', 'gif', '/*', '*/', '{', 'xv', 'upgrade', '----------------------------------------------------------------------------', 'training', '------------------------------------------------------------------------------', 'colors', 'ati', 'card.', 'program.', 'jpeg', '(gary', 'gary', 'microsoft', 'windows,', '_', 'sweden', 'tape', 'rochester', '256', 'install', ';', 'cd', 'shipping', 'dos', 'mouse', 'resource', 'postscript', 'center,', 'fonts', 'edge', 'ran', 'package', 'block', 'faster', 'software,', 'driver', 'card,', 'lee', 'corp.', 'agencies', 'distribution', 'disks', 'companies', 'tel:', 'macintosh', 'scsi', 'announced', 'shuttle', 'sci.space', 'font', '300', 'info.', 'mb', 'widget', 'windows.', 'colorado', 'motif', 'monitors', 'player', 'radar', 'satellite', 'minutes', 'mhz', 'floppy', 'isa', 'installed', 'louis', 'os/2', '-------------------------------------------------------------------------------', 'fix', 'monitor', 'quadra', 'clock', 'bios', 'boards', 'controller', 'motorola', 'electronics', 'centris', 'select', 'modem', 'coverage', 'hd', 'rates', 'smith)', 'year.', 'cheaper', 'annual', '****', 'drive.', 'netcom', 'guest)', 'rom', 'cancer', '(gordon', 'georgia', 'hst', 'sci.med', 'meg', 'file:', 'chips', 'msg', 'auto', 'expansion', 'administration', 'cable', 'temperature', 'simms', 'ide', 'russian', '$2', 'sci.electronics', 'dc', 'leading', 'x11r5', 'vehicle', 'comp.os.ms-windows.misc', 'buffalo', 'db', 'dod', 'battery', 'motherboard', 'insurance', 'sale:', 'bike', 'dealer', 'xterm', 'encryption', 'encrypted', 'morris', 'comp.sys.ibm.pc.hardware', 'winning', 'season', 'comp.sys.mac.hardware', 'rear', 'rocket', 'comp.windows.x', 'honda', 'hedrick@geneva.rutgers.edu', 'spacecraft', 'misc.forsale', 'clutch', 'braves', 'bmw', 'rec.autos', 'talk.politics.guns', 'attorney', 'batf', 'detroit', 'rec.motorcycles', 'lunar', 'rec.sport.baseball', 'espn', 'playoff', 'rec.sport.hockey', 'nhl', 'leafs', '55.0', '(--)', 'escrow', 'firearms', 'talk.politics.misc', 'christian@aramis.rutgers.edu', 'hedrick@athos.rutgers.edu', 'jews?', 'armenian', 'myers:', 'sera@zuma.uucp', '(serdar', 'argic)', 'x-soviet', 'armenia', 'talk.politics.mideast', 'arabs', 'armenians', 'adl', 'stephanopoulos:']\n"
     ]
    }
   ],
   "source": [
    "print(final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SucV4mfsNtUM"
   },
   "outputs": [],
   "source": [
    "database = np.zeros((19997,len(final_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t5jTHFs4NtUR"
   },
   "outputs": [],
   "source": [
    "def clean(word):\n",
    "    while len(word)>0 and word[-1] in punc:\n",
    "        word = word[:-1]\n",
    "    while len(word)>0 and word[0] in punc:\n",
    "        word = word[1:]\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GeHpySU6NtUT"
   },
   "outputs": [],
   "source": [
    "def no_num(s):\n",
    "    for i in range(len(s)):\n",
    "        if s[i] in num:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "RHqtwPIaNtUV",
    "outputId": "17550e82-fdc8-4a97-cdeb-d473d7adfd30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19997\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for i in range(20):\n",
    "    for j in range(len(data[classes[i]])):\n",
    "        path = \"./20_newsgroups/\"+classes[i]+\"/\"+data[classes[i]][j]\n",
    "        text = open(path, 'r', errors='ignore').read()\n",
    "        for word in text.split():\n",
    "            word=word.lower()\n",
    "            if word not in StopWords and word not in block_words:\n",
    "                if word in final_words:\n",
    "                    idx = final_words.index(word)\n",
    "                    database[counter][idx] += 1\n",
    "        counter += 1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YwBwIS0DNtUY"
   },
   "outputs": [],
   "source": [
    "sum_array = np.sum(database,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "w8uNR6kSNtUa",
    "outputId": "35f2204f-911b-4947-d8e8-7e203516007a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19997,)"
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = []\n",
    "for i in range(len(classes)):\n",
    "    files = os.listdir('./20_newsgroups/' + classes[i])\n",
    "    for j in range(len(files)):\n",
    "        y.append(i)\n",
    "y = np.array(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pA0e6Fz-NtUe"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(database, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "BDSzYS4PNtUf",
    "outputId": "1af5ae1d-8ea0-4b1f-9829-c4cc791b5464"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8696405947856238, 0.8326)"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "train_score = clf.score(x_train, y_train)\n",
    "test_score = clf.score(x_test, y_test)\n",
    "\n",
    "train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gY8xJLhpNtUi"
   },
   "outputs": [],
   "source": [
    "f_list = final_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nEShIZOfNtUj"
   },
   "outputs": [],
   "source": [
    "def fit(x_train, y_train):\n",
    "\n",
    "    count={}\n",
    "    set_class = set(y_train)            \n",
    "    for current_class in set_class:\n",
    "        count[current_class] = {}\n",
    "        count[\"total_data\"] = len(y_train)\n",
    "        \n",
    "        ##Rows whose class is current_class\n",
    "        current_class_rows = (y_train == current_class)\n",
    "        \n",
    "        x_train_current = x_train[current_class_rows]\n",
    "        y_train_current = y_train[current_class_rows]\n",
    "        \n",
    "        sums = 0\n",
    "        for i in range(len(f_list)):\n",
    "            ## For each class, calculating total frequency of a feature \n",
    "            count[current_class][f_list[i]] = x_train_current[:,i].sum()\n",
    "            sums = sums + count[current_class][f_list[i]]\n",
    "        \n",
    "        ##Calculating total count of words of a class\n",
    "        count[current_class][\"total_count\"] = sums\n",
    "        \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EiPcRSl8NtUm"
   },
   "outputs": [],
   "source": [
    "def probability(dictionary, row, current_class):\n",
    "    ## class_prob = log of probability of the current class = log(no of documents having class as current_class)/ (total number of documents)\n",
    "    class_prob = np.log(dictionary[current_class][\"total_count\"]) - np.log(dictionary[\"total_data\"])\n",
    "    total_prob = class_prob\n",
    "    \n",
    "    \n",
    "    for i in range(len(row)):\n",
    "        ##Numerator\n",
    "        word_count = dictionary[current_class][f_list[i]] + 1     \n",
    "        ## Denominator\n",
    "        total_count = dictionary[current_class][\"total_count\"] + len(f_list)\n",
    "        ## Add 1 to numerator and len(row) in denominator for laplace correction\n",
    "        \n",
    "        ## Log Probabilty of a word \n",
    "        word_prob = np.log(word_count) - np.log(total_count)\n",
    "        \n",
    "        ##Calculating probability frequency number of times\n",
    "        for j in range(int(row[i])):\n",
    "            total_prob += word_prob\n",
    "        \n",
    "    return total_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bLDaYgT1NtUo"
   },
   "outputs": [],
   "source": [
    "def predictSinglePoint(row, dictionary):\n",
    "    classes = dictionary.keys()\n",
    "    \n",
    "    ##Initialising best_prob and best_class as very low count\n",
    "    \n",
    "    best_prob = -1000\n",
    "    best_class = -1\n",
    "    first_iter = True\n",
    "    \n",
    "    for current_class in classes:\n",
    "        if(current_class == \"total_data\"):\n",
    "            continue\n",
    "        \n",
    "        ##Calculating probabilty that the given row belong to current_class\n",
    "        prob_current_class = probability(dictionary, row, current_class)\n",
    "        \n",
    "        ##For first iteration we set the best_prob to be the probabilty that row is of first class and best_class to be first class\n",
    "        ##For rest iteration, we check if the probabilty that row is of the current_class is greater than the best_prob then we update best_prob and best_class.\n",
    "        if(first_iter or prob_current_class > best_prob):\n",
    "            best_prob = prob_current_class\n",
    "            best_class = current_class\n",
    "        \n",
    "        first_iter = False\n",
    "    \n",
    "    ## Return the best class which has maximum probabilty.\n",
    "    return best_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GTMvYhstNtUq"
   },
   "outputs": [],
   "source": [
    "def predict(x_test, dictionary):\n",
    "    ## Initialise a list which contain the predictions\n",
    "    y_pred_self = []\n",
    "    \n",
    "    ##Iterate through each row in x_test\n",
    "    for j in range(len(x_test)):\n",
    "        \n",
    "        ##Calculate the prediction of the class to which the row belong to.\n",
    "        pred_class = predictSinglePoint(x_test[j,:], dictionary) \n",
    "        \n",
    "        ##Append the predicted class to our list\n",
    "        y_pred_self.append(pred_class)\n",
    "    \n",
    "    ##Return the list of predictions\n",
    "    return y_pred_self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ih6Fiw9ONtUt"
   },
   "outputs": [],
   "source": [
    "dictionary = fit(x_train, y_train)\n",
    "\n",
    "##Testing the model \n",
    "y_pred_self = predict(x_test, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "C56hnclhNtUu",
    "outputId": "329d6b11-2675-4976-f390-659d233dc5fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for self-implemented Naive Bayes -  0.8334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy for self-implemented Naive Bayes - \", accuracy_score(y_test, y_pred_self))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "TextClassification.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
